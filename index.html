<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="Pointing Visuomotor Policies Towards Visual Robustness">
  <meta property="og:title" content="Augmented Reality for RObots (ARRO): Pointing Visuomotor Policies Towards Visual Robustness"/>
  <meta property="og:description" content="Pointing Visuomotor Policies Towards Visual Robustness"/>
  <meta property="og:url" content="https://augmented-reality-for-robots.github.io/"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <!-- <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/> -->


  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="Domain Adaptation, Imitation Learning, Scene Abstraction">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>ARRO</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Augmented Reality for RObots (ARRO):<br>Pointing Visuomotor Policies Towards Visual Robustness</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://www.linkedin.com/in/reihaneh-mirjalili-b112a8251/" target="_blank">Reihaneh Mirjalili</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a href="https://www.linkedin.com/in/juelg/" target="_blank">Tobias JÃ¼lg</a><sup>*</sup>,</span>
                  <span class="author-block">
                    <a href="https://www.utn.de/person/prof-dr-florian-walter/" target="_blank">Florian Walter</a>,
                  </span>
                  <span class="author-block">
                    <a href="https://www.utn.de/person/wolfram-burgard-2/" target="_blank">Wolfram Burgard</a>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">University of Technology Nuremberg</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                      <!-- ArXiv abstract Link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/abs/2505.08627" target="_blank"
                          class="external-link button is-normal is-rounded is-dark">
                          <span class="icon">
                            <i class="ai ai-arxiv"></i>
                          </span>
                          <span>arXiv</span>
                        </a>
                      </span>
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2505.08627" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>



                    <!-- YouTube Video Link -->
                    <span class="link-block">
                      <a href="https://youtu.be/FWC8U7WeRFk?si=7_A39UWGxg275XcE" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fab fa-youtube"></i>
                        </span>
                        <span>Video</span>
                      </a>
                    </span>

                  <!-- Github link -->
                  <!-- <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span> -->


            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="section mt-0">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <img src="static/images/mai_diagram_ARRO.png" alt="ARRO diagram" style="width: 100%; max-width: 1100px; margin: auto;">
      </div>
    </div>
  </div>
</section>








<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Visuomotor policies trained on human expert demonstrations have recently shown strong performance across a wide range of robotic manipulation tasks.
            However, these policies remain highly sensitive to domain shifts stemming from background or robot embodiment changes, which limits their generalization capabilities.
            In this paper, we present ARRO, a novel calibration-free visual representation that leverages zero-shot open-vocabulary segmentation and object detection models to efficiently mask out task-irrelevant regions of the scene without requiring additional training.
            By filtering visual distractors and overlaying virtual guides during both training and inference, ARRO improves robustness to scene variations and reduces the need for additional data collection.
            We extensively evaluate ARRO with Diffusion Policy on several tabletop manipulation tasks in both simulation and real-world environments, and further demonstrate its compatibility and effectiveness with generalist robot policies, such as Octo and OpenVLA.
            Across all settings in our evaluation, ARRO yields consistent performance gains, allows for selective masking to choose between different objects, and shows robustness even to challenging segmentation conditions.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->






<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-multiline is-centered has-text-centered">
      
      <div class="column is-half">
        <video autoplay loop controls muted playsinline>
          <source src="static/videos/training.mp4" type="video/mp4">
        </video>
      </div>

      <div class="column is-half">
        <video autoplay loop controls muted playsinline>
          <source src="static/videos/masked.mp4" type="video/mp4">
        </video>
      </div>

      <div class="column is-half">
        <video autoplay loop controls muted playsinline>
          <source src="static/videos/arro.mp4" type="video/mp4">
        </video>
      </div>

      <div class="column is-half">
        <video autoplay loop controls muted playsinline>
          <source src="static/videos/inference.mp4" type="video/mp4">
        </video>
      </div>

    </div>
  </div>
</section>


<div class="columns is-centered">
  <div class="column is-two-thirds">

    <p class="is-size-5 has-text-justified">
      Visuomotor policies trained through imitation learning often fail to generalize across visual domain shifts.
      Minor changes in background, lighting, or robot appearance at test time can lead to substantial performance drops.
    </p>
    <p class="is-size-5 has-text-justified mt-3">
      In the example above, the robot learns to <em>drop a cube into a box and close the lid</em>.
      At inference, the same task is attempted in a visually altered scene, with changes in background, distractors, and robot embodiment.
      While standard policies break, <strong>ARRO</strong> filters out irrelevant content, retaining only the gripper, cube, and box, 
      and overlays them on a structured virtual background.
      This abstraction makes ARRO <strong>robust to visual variation</strong>.
      To isolate the role of spatial cues, we also provide an ablation using a plain black background.


    </p>
  </div>
</div>





<div class="columns is-centered">
  <div class="column is-two-thirds">
    <h2 class="title is-4"><strong>ARRO Generalizes Across Tasks and Scenes</strong></h2>

  </div>
</div>



<section class="section">
  <div class="container">
    <div class="columns is-vcentered">

      <!-- 4 videos stacked in 2x2 layout -->
      <div class="column">
        <div class="columns is-multiline is-gapless">

          <div class="column is-half">
            <video autoplay loop controls muted playsinline style="width: 99%;">
              <source src="static/videos/pick.mp4" type="video/mp4">
            </video>
          </div>

          <div class="column is-half">
            <video autoplay loop controls muted playsinline style="width: 99%;">
              <source src="static/videos/push.mp4" type="video/mp4">
            </video>
          </div>

          <div class="column is-half">
            <video autoplay loop controls muted playsinline style="width: 99%;">
              <source src="static/videos/box.mp4" type="video/mp4">
            </video>
          </div>

          <div class="column is-half">
            <video autoplay loop controls muted playsinline style="width: 99%;">
              <source src="static/videos/doll.mp4" type="video/mp4">
            </video>
          </div>

        </div>
      </div>

      <!-- Bar Plot aligned next to 2x2 grid -->
      <div class="column is-narrow">
        <img src="static/images/bar_plot.png" alt="ARRO Results" style="height: 370px;">
      </div>


    </div>
  </div>
</section>



<div class="columns is-centered">
  <div class="column is-two-thirds">


    <p class="is-size-5 has-text-justified">


      The Vanilla Diffusion Policy performs poorly under domain shifts due to its dependence on raw visual features. 
      The Masked Diffusion Policy does better by removing distractors but still underperforms compared to ARRO, likely because it also removes useful cues.
       ARRO outperforms both by filtering out irrelevant information while restoring a consistent background, leading to improved robustness and generalization.
    </p>
  </div>
</div>






<div class="columns is-centered">
  <div class="column is-two-thirds">
    <h2 class="title is-4"><strong>Zero-Shot Spatial Reasoning with ARRO</strong></h2>

  </div>
</div>


<section class="section">
  <div class="container">
    <div class="columns is-vcentered">

      <div class="column is-narrow">
        <img src="static/images/command.png" alt="Preference Results" style="height: 230px;">
      </div>

      <!-- Video: Preference -->
      <div class="column">
        <video autoplay loop controls muted playsinline style="width: 100%; max-height: 320px;">
          <source src="static/videos/distractor.mp4" type="video/mp4">
        </video>
      </div>

      <!-- Bar plot: Preference -->
      <div class="column is-narrow">
        <img src="static/images/distractor.png" alt="Preference Results" style="height: 230px;">
      </div>

    </div>
  </div>
</section>




<div class="columns is-centered">
  <div class="column is-two-thirds">


    <p class="is-size-5 has-text-justified">
      In this setup, the robot receives a natural language instruction: <em>âPush the blue cube that is farther from the yellow cube to the red cross.â</em>
       Executing this task requires spatial reasoning and grounding language in the visual scene.

      Standard visuomotor policies often fail when the scene layout changes or distractors are present.
       ARRO addresses this by abstracting away irrelevant regions and retaining only the gripper and target object.

      This abstraction supports robust relational reasoning. 
      As shown above, ARRO generalizes zero-shot to new configurations, succeeding in both <em>left/right</em> and <em>closer/farther</em> variants without additional training.
    </p>
  </div>
</div>


<div class="columns is-centered">
  <div class="column is-two-thirds">
    <h2 class="title is-4"><strong>Handling Textures and Object Shape Variation</strong></h2>

  </div>
</div>



<section class="section">
  <div class="container has-text-centered">
    <video autoplay loop controls muted playsinline style="max-width: 60%; height: auto;">
      <source src="static/videos/doll_box_blend.mp4" type="video/mp4">
    </video>
  </div>
</section>


<div class="columns is-centered">
  <div class="column is-two-thirds">


    <p class="is-size-5 has-text-justified">
      In this visualization, we zoom into two visually rich tasks. Despite the presence of rich textures, non-rigid shapes, and occlusion,
      ARRO's segmentation module consistently identifies and preserves the task-relevant components: the gripper and manipulable objects.

      This robustness in visual abstraction enables generalist policies to execute precise actions even in the presence of complex, 
      unfamiliar visual elementsâwithout any additional training or fine-tuning.
    </p>
  </div>
</div>














<div class="columns is-centered">
  <div class="column is-two-thirds">
    <h2 class="title is-4"><strong>Cross Embodiment</strong></h2>

  </div>
</div>




  <section class="section hero is-small">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column">
          <img src="static/images/crossx.svg" alt="Cross embodiment visualization" width="100%" />
          <!-- <div class="content has-text-justified">
            <p>Some text
            </p>
          </div> -->
          <div class="hero-body">
            <div class="columns is-vcentered interpolation-panel">
              <div class="column  has-text-centered">
                <h5><b>DP Vanilla</b></h5>
                <h5 style="font-size:30px;">â</h5>
                <video autoplay controls muted loop playsinline width="90%">
                  <source src="static/videos/crossx_dp_vanilla.mp4" type="video/mp4">
                </video>
              </div>
              <div class="column  has-text-centered">
                <h5><b>DP ARRO</b></h5>
                <h5 style="font-size:30px;">â</h5>
                <video autoplay controls muted loop playsinline width="90%">
                  <source src="static/videos/crossx_dp_arro.mp4" type="video/mp4">
                </video>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>






<div class="columns is-centered">
  <div class="column is-two-thirds">

    <p class="is-size-5 has-text-justified">
      To assess how well our ARRO policies generalize across different robotic embodiments, 
      we trained them on the FR3 robot in simulation and evaluated their performance on a distinct UR5e embodiment. 
      While baseline diffusion policies suffered a complete performance collapse when transferred, 
      ARRO and masked variants demonstrated strong cross-embodiment generalization with only minor reductions in success rates. 
      This robustness is attributed to ARROâs architecture, which masks embodiment-specific features and operates in a Cartesian control space, 
      ensuring consistent behavior across varied physical forms. 
      These results underscore ARRO's potential for scalable deployment across heterogeneous robotic platforms.


    </p>
  </div>
</div>








<div class="columns is-centered">
  <div class="column is-two-thirds">
    <h2 class="title is-4"><strong>Real-to-Sim</strong></h2>
  </div>
</div>




  <section class="section hero is-small">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column">
          <img src="static/images/real2sim.svg" alt="Real to sim visualization" width="100%" />
          <!-- <div class="content has-text-justified">
            <p>Some text
            </p>
          </div> -->
          <div class="hero-body">
            <div class="columns is-vcentered interpolation-panel">
              <div class="column  has-text-centered">
                <h5><b>OpenVLA Vanilla</b></h5>
                <h5 style="font-size:30px;">â</h5>
                <video autoplay controls muted loop playsinline width="90%">
                  <source src="static/videos/real2sim_openvla_vanilla.mp4" type="video/mp4">
                </video>
              </div>
              <div class="column  has-text-centered">
                <h5><b>OpenVLA ARRO</b></h5>
                <h5 style="font-size:30px;">â</h5>
                <video autoplay controls muted loop playsinline width="90%">
                  <source src="static/videos/real2sim_openvla_arro.mp4" type="video/mp4">
                </video>
              </div>
            </div>
            <br>
            <img src="static/images/all_rewards.svg" alt="Real to sim rewards for all models"
              width="100%" />
          </div>
        </div>
      </div>
    </div>
  </section>





<div class="columns is-centered">
  <div class="column is-two-thirds">

    <p class="is-size-5 has-text-justified">
    We evaluated Diffusion Policy, Octo, and OpenVLA for real-to-sim transfer on the pick-v2 task. 
    While all models performed well in the real world, their success rates dropped sharply in simulation. 
    OpenVLA with ARRO and black masking significantly outperformed its vanilla version, retaining strong performance across domains.
    As shown, ARRO enables successful task execution in sim and consistently higher rewards, 
    highlighting its effectiveness in bridging real-to-sim gaps.


    </p>
  </div>
</div>



















<!-- Image carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <img src="static/images/carousel1.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          First image description.
        </h2>
      </div>
      <div class="item">
        <img src="static/images/carousel2.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Second image description.
        </h2>
      </div>
      <div class="item">
        <img src="static/images/carousel3.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
         Third image description.
       </h2>
     </div>
     <div class="item">
      <img src="static/images/carousel4.jpg" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">
        Fourth image description.
      </h2>
    </div>
  </div>
</div>
</div>
</section> -->
<!-- End image carousel -->




<!-- Youtube video -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End youtube video -->


<!-- Video carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            <source src="static/videos/carousel1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            <source src="static/videos/carousel2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\
            <source src="static/videos/carousel3.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End video carousel -->






<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->


<!-- BibTeX citation section -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    
    <div class="box">
      <pre><code id="bibtex-entry">@article{mirjalili2025augmented,
  title={{Augmented Reality for RObots (ARRO)}: {P}ointing Visuomotor Policies Towards Visual Robustness},
  author={Mirjalili, Reihaneh and J{\"u}lg, Tobias and Walter, Florian and Burgard, Wolfram},
  journal={arXiv preprint arXiv:2505.08627},
  year={2025}
}</code></pre>
      <button class="button is-small is-link mt-2" onclick="copyBibtex()">Copy to Clipboard</button>
    </div>
  </div>
</section>

<!-- Copy to clipboard script -->
<script>
  function copyBibtex() {
    const bibtex = document.getElementById("bibtex-entry").innerText;
    navigator.clipboard.writeText(bibtex);
  }
</script>




  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content has-text-centered">
            Website template borrowed from <span class="dnerf"><a
                href="https://github.com/nerfies/nerfies.github.io">Nerfies</a></span>.
          </div>
        </div>
      </div>
    </div>
  </footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

<!-- End of Statcounter Code -->

  </body>
  </html>
